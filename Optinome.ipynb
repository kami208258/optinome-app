{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df61c498",
   "metadata": {},
   "source": [
    "# LivenProteins â€” Bioreactor Optimization (Template Rebuild)\n",
    "\n",
    "**Purpose:** Predict **OD600** and **Collagen** from process parameters (DO, Airflow sL/h, Agitation rpm, pH, Feed rate/total, residual glycerol/methanol).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d97686c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_DIR: /Users/peyma/Desktop/PROJECT 24-0048 (CII Prototype Strain Bioreactor Validation)\n",
      "EXTRACT_DIR: /Users/peyma/Desktop/PROJECT 24-0048 (CII Prototype Strain Bioreactor Validation)\n",
      "OUTPUT_DIR: /Users/peyma/Desktop/PROJECT 24-0048 (CII Prototype Strain Bioreactor Validation)/outputs\n"
     ]
    }
   ],
   "source": [
    "# === Global paths ===\n",
    "OUTPUT_DIR = Path(\"optinome_outputs\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "# === Setup ===\n",
    "from pathlib import Path\n",
    "\n",
    "# ðŸ‘‰ CHANGE THIS TO YOUR REAL PROJECT FOLDER (this matches your terminal)\n",
    "PROJECT_DIR = Path(\"/Users/peyma/Desktop/PROJECT 24-0048 (CII Prototype Strain Bioreactor Validation)\")\n",
    "\n",
    "# If all your EXP decks & summary files are already in this folder (or subfolders):\n",
    "EXTRACT_DIR = PROJECT_DIR  # we just walk the project tree directly\n",
    "\n",
    "# Where plots and outputs will be saved\n",
    "OUTPUT_DIR = PROJECT_DIR / \"outputs\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)\n",
    "print(\"EXTRACT_DIR:\", EXTRACT_DIR)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a478899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Helpers ===\n",
    "def iter_excels(root: Path, priority_names: set, limit: int):\n",
    "    files = []\n",
    "    for r, _, fs in os.walk(root):\n",
    "        for f in fs:\n",
    "            if f.lower().endswith(('.xls', '.xlsx')):\n",
    "                files.append(Path(r)/f)\n",
    "    files = sorted(files, key=lambda p: (0 if p.name in priority_names else 1, p.name))\n",
    "    return files[:limit]\n",
    "\n",
    "def get_time_hours(series):\n",
    "    s = series\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        return pd.to_numeric(s, errors='coerce')\n",
    "    dt = pd.to_datetime(s, errors='coerce')\n",
    "    if dt.notna().sum() >= 2:\n",
    "        return (dt - dt.min()) / np.timedelta64(1,'h')\n",
    "    num = pd.to_numeric(s, errors='coerce')\n",
    "    if num.notna().sum() >= 2:\n",
    "        return num.astype(float)\n",
    "    return pd.Series(np.arange(len(s)), index=s.index, dtype=float)\n",
    "\n",
    "re_do_pv = re.compile(r\"DO\\s*\\d+\\.PV\\s*\\[\\s*%DO\\s*\\]\", re.IGNORECASE)\n",
    "re_do_sp = re.compile(r\"DO\\.SP\\[\\s*\\d+\\s*\\]\\s*\\[\\s*%DO\\s*\\]\", re.IGNORECASE)\n",
    "re_fa_pv = re.compile(r\"FA\\s*\\d+\\.PV\\s*\\[\\s*mL/h\\s*\\]\", re.IGNORECASE)\n",
    "\n",
    "def detect_col(cols, tests):\n",
    "    for t in tests:\n",
    "        for c in cols:\n",
    "            if t(c):\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "def parse_growth(xf: ExcelFile):\n",
    "    sh = next((s for s in xf.sheet_names if s.strip().lower()=='growth'), None)\n",
    "    if sh is None: return None\n",
    "    df = xf.parse(sh)\n",
    "    if df.empty: return None\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    cols = list(df.columns)\n",
    "    time_col = detect_col(cols, [lambda c: any(k in c.lower() for k in ['timestamp','time','duration','elapsed','hour','hr','date'])])\n",
    "    od_col   = detect_col(cols, [lambda c: 'od600' in c.lower() or re.search(r\"\\bod\\s*600\\b\", c, flags=re.IGNORECASE)])\n",
    "    do_pv_col = detect_col(cols, [lambda c: re_do_pv.search(c) is not None])\n",
    "    do_sp_col = detect_col(cols, [lambda c: re_do_sp.search(c) is not None])\n",
    "    fa_pv_col = detect_col(cols, [lambda c: re_fa_pv.search(c) is not None])\n",
    "    t = get_time_hours(df[time_col]) if time_col else pd.Series(np.arange(len(df)))\n",
    "    return pd.DataFrame({'time_hours': t,\n",
    "                         'od600': pd.to_numeric(df[od_col], errors='coerce') if od_col in df.columns else np.nan,\n",
    "                         'do_pv': pd.to_numeric(df[do_pv_col], errors='coerce') if do_pv_col in df.columns else np.nan,\n",
    "                         'do_sp': pd.to_numeric(df[do_sp_col], errors='coerce') if do_sp_col in df.columns else np.nan,\n",
    "                         'feed_ml_h': pd.to_numeric(df[fa_pv_col], errors='coerce') if fa_pv_col in df.columns else np.nan})\n",
    "\n",
    "def col_letter_idx(letter: str) -> int:\n",
    "    total=0\n",
    "    for ch in letter.upper():\n",
    "        total=total*26+(ord(ch)-ord('A')+1)\n",
    "    return total-1\n",
    "\n",
    "def parse_data(xf: ExcelFile):\n",
    "    sh = next((s for s in xf.sheet_names if s.strip().lower()=='data'), None)\n",
    "    if sh is None:\n",
    "        sh = next((s for s in xf.sheet_names if 'data' in s.strip().lower()), None)\n",
    "    if sh is None: return None\n",
    "    df = xf.parse(sh, header=0)\n",
    "    if df.empty: return None\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    cols = list(df.columns)\n",
    "    time_col = detect_col(cols, [lambda c: any(k in c.lower() for k in ['timestamp','time','duration','elapsed','hour','hr','date'])])\n",
    "    t = get_time_hours(df[time_col]) if time_col in df.columns else get_time_hours(df.iloc[:,0])\n",
    "    def get_by_idx(i):\n",
    "        return pd.to_numeric(df.iloc[:, i], errors='coerce') if i<df.shape[1] else pd.Series([np.nan]*len(df), index=df.index)\n",
    "    return pd.DataFrame({'time_hours': t,\n",
    "                         'do_data': get_by_idx(col_letter_idx('F')),\n",
    "                         'air_slph': get_by_idx(col_letter_idx('G')),\n",
    "                         'agitation_rpm': get_by_idx(col_letter_idx('O')),\n",
    "                         'ph_data': get_by_idx(col_letter_idx('Q'))})\n",
    "\n",
    "def parse_hplc(xf: ExcelFile):\n",
    "    sh = next((s for s in xf.sheet_names if 'hplc' in s.strip().lower()), None)\n",
    "    if sh is None: return None\n",
    "    df = xf.parse(sh)\n",
    "    if df.empty: return None\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    cols = list(df.columns)\n",
    "    time_col = detect_col(cols, [lambda c: any(k in c.lower() for k in ['timestamp','time','sample time','collection time','date','elapsed','hour','hr'])])\n",
    "    t = get_time_hours(df[time_col]) if time_col in df.columns else get_time_hours(df.iloc[:,0])\n",
    "    gly_col = detect_col(cols, [lambda c: ('glycerol' in c.lower() or 'glyc' in c.lower() or 'gly' in c.lower()) and any(u in c.lower() for u in ['g/l','mg/l','conc','concentration','area','peak'])])\n",
    "    meoh_col= detect_col(cols, [lambda c: ('methanol' in c.lower() or 'meoh' in c.lower()) and any(u in c.lower() for u in ['g/l','mg/l','conc','concentration','area','peak'])])\n",
    "    return pd.DataFrame({'time_hours': t,\n",
    "                         'glycerol': pd.to_numeric(df[gly_col], errors='coerce') if gly_col in df.columns else np.nan,\n",
    "                         'methanol': pd.to_numeric(df[meoh_col], errors='coerce') if meoh_col in df.columns else np.nan})\n",
    "\n",
    "def parse_compilation(xf: ExcelFile, name: str):\n",
    "    if name.lower()!='data_compilation.xlsx':\n",
    "        return None\n",
    "    sh = xf.sheet_names[0]\n",
    "    df = xf.parse(sh)\n",
    "    if df.empty: return None\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    cols = list(df.columns)\n",
    "    time_col = detect_col(cols, [lambda c: any(k in c.lower() for k in ['time','timestamp','date','hour','hr','duration','elapsed'])])\n",
    "    t = get_time_hours(df[time_col]) if time_col in df.columns else pd.Series([np.nan]*len(df))\n",
    "    coll_col = detect_col(cols, [lambda c: any(x in c.lower() for x in ['collagen','titre','titer','hydroxyproline','total protein','mg/l','g/l'])])\n",
    "    return pd.DataFrame({'time_hours': t,\n",
    "                         'collagen': pd.to_numeric(df[coll_col], errors='coerce') if coll_col in df.columns else np.nan})\n",
    "\n",
    "def parse_feeding(xf: ExcelFile):\n",
    "    feed_sheets = [s for s in xf.sheet_names if 'feed' in s.strip().lower()]\n",
    "    if not feed_sheets: return None\n",
    "    totals = []\n",
    "    for sh in feed_sheets:\n",
    "        try:\n",
    "            df = xf.parse(sh)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if df.empty: continue\n",
    "        cand = [c for c in df.columns if re.search(r'(total|used|consumed|feed)', str(c), flags=re.IGNORECASE)]\n",
    "        if cand:\n",
    "            sub = pd.to_numeric(df[cand], errors='coerce')\n",
    "            val = np.nansum(sub.values)\n",
    "            if np.isfinite(val) and val>0: totals.append(val)\n",
    "        else:\n",
    "            coerced = df.apply(pd.to_numeric, errors='coerce')\n",
    "            val = np.nansum(coerced.values)\n",
    "            if np.isfinite(val) and val>0: totals.append(val)\n",
    "    if not totals: return None\n",
    "    return float(np.nanmax(totals))\n",
    "\n",
    "def merge_asof_per_file(base: pd.DataFrame, add: pd.DataFrame, cols, tol=0.5):\n",
    "    if base.empty or add is None or add.empty:\n",
    "        return base\n",
    "    l = base.dropna(subset=['time_hours']).sort_values('time_hours')\n",
    "    r = add.dropna(subset=['time_hours']).sort_values('time_hours')\n",
    "    if l.empty or r.empty:\n",
    "        return base\n",
    "    m = pd.merge_asof(l, r[['time_hours'] + cols], on='time_hours', direction='nearest', tolerance=tol)\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "203d6d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Extraction & Merge (run cell) ===\n",
    "PRIORITY = []\n",
    "PROCESS_LIMIT = None\n",
    "excels = iter_excels(EXTRACT_DIR, PRIORITY, PROCESS_LIMIT)\n",
    "runs = []\n",
    "for p in excels:\n",
    "    try:\n",
    "        xf = ExcelFile(p)\n",
    "    except Exception:\n",
    "        continue\n",
    "    g = parse_growth(xf)\n",
    "    d = parse_data(xf)\n",
    "    h = parse_hplc(xf)\n",
    "    c = parse_compilation(xf, p.name)\n",
    "    feed_total = parse_feeding(xf)\n",
    "    if g is None:\n",
    "        continue\n",
    "    df = g.copy()\n",
    "def merge_asof_per_file(base, add, cols, tol=0.1):\n",
    "    if add is None:\n",
    "        return base\n",
    "\n",
    "    l = base.copy()\n",
    "    r = add.copy()\n",
    "\n",
    "    # If time_hours is missing we just skip\n",
    "    if 'time_hours' not in l.columns or 'time_hours' not in r.columns:\n",
    "        return base\n",
    "\n",
    "    # ðŸ”‘ Make sure both sides use the same dtype\n",
    "    l['time_hours'] = pd.to_numeric(l['time_hours'], errors='coerce').astype('float64')\n",
    "    r['time_hours'] = pd.to_numeric(r['time_hours'], errors='coerce').astype('float64')\n",
    "\n",
    "    # Drop rows where time is NaN\n",
    "    l = l.dropna(subset=['time_hours'])\n",
    "    r = r.dropna(subset=['time_hours'])\n",
    "\n",
    "    # merge_asof requires sorted keys\n",
    "    l = l.sort_values('time_hours')\n",
    "    r = r.sort_values('time_hours')\n",
    "\n",
    "    if l.empty or r.empty:\n",
    "        return base\n",
    "\n",
    "    m = pd.merge_asof(\n",
    "        l,\n",
    "        r[['time_hours'] + cols],\n",
    "        on='time_hours',\n",
    "        direction='nearest',\n",
    "        tolerance=tol,\n",
    "    )\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7790d455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('snapshots/model_inputs_snapshot_template.csv')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "out_dir = Path(\"snapshots\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "snap_path = out_dir / \"model_inputs_snapshot_template.csv\"\n",
    "master.to_csv(snap_path, index=False)\n",
    "snap_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c781aade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('model_outputs/model_report_template.txt')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Choose a folder inside your project\n",
    "out_dir = Path(\"model_outputs\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save file HERE instead of /mnt/data\n",
    "report_path = out_dir / \"model_report_template.txt\"\n",
    "report_path.write_text('\\n'.join(report))\n",
    "\n",
    "report_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2b25dce9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/var/folders/2n/bygt0bbd55vbyhzgw0fz17z80000gn/T/ipykernel_17738/1859623321.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m optinome_app \u001b[38;5;28;01mimport\u001b[39;00m PROJECT_DIR, build_master\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m master = build_master(PROJECT_DIR)\n\u001b[32m      3\u001b[39m print(\u001b[33m\"Master shape:\"\u001b[39m, master.shape)\n\u001b[32m      4\u001b[39m \n",
      "\u001b[32m~/Desktop/PROJECT 24-0048 (CII Prototype Strain Bioreactor Validation)/optinome_app.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(project_dir)\u001b[39m\n\u001b[32m    218\u001b[39m \n\u001b[32m    219\u001b[39m     Returns an empty DataFrame \u001b[38;5;28;01mif\u001b[39;00m:\n\u001b[32m    220\u001b[39m     - neither the file nor its parent folder look like an EXP\n\u001b[32m    221\u001b[39m     - the workbook cannot be opened\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     - \u001b[38;5;28;01mor\u001b[39;00m no valid data sheets are parsed.\n\u001b[32m    223\u001b[39m     \"\"\"\n\u001b[32m    224\u001b[39m     name = path.name\n\u001b[32m    225\u001b[39m     parent_name = path.parent.name\n",
      "\u001b[32m~/Desktop/PROJECT 24-0048 (CII Prototype Strain Bioreactor Validation)/optinome_app.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    195\u001b[39m \n\u001b[32m    196\u001b[39m     df[\u001b[33m\"time_hours\"\u001b[39m] = df[time_col].apply(parse_time_to_hours)\n\u001b[32m    197\u001b[39m     df = df.dropna(subset=[\u001b[33m\"time_hours\"\u001b[39m])\n\u001b[32m    198\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     df[\u001b[33m\"exp_id\"\u001b[39m] = exp_id\n\u001b[32m    200\u001b[39m     \u001b[38;5;66;03m# Try to infer vessel column if present\u001b[39;00m\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"vessel\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m df.columns:\n\u001b[32m    202\u001b[39m         \u001b[38;5;66;03m# For now, one vessel per sheet\u001b[39;00m\n",
      "\u001b[32m~/Desktop/PROJECT 24-0048 (CII Prototype Strain Bioreactor Validation)/optinome_app.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(df_raw, sheet_name, exp_id)\u001b[39m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m isinstance(val, (int, float, np.integer, np.floating)):\n\u001b[32m    149\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m float(val)\n\u001b[32m    150\u001b[39m \n\u001b[32m    151\u001b[39m     s = str(val).strip()\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m s:\n\u001b[32m    153\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# Try simple float first\u001b[39;00m\n",
      "\u001b[32m~/Desktop/PROJECT 24-0048 (CII Prototype Strain Bioreactor Validation)/venv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10397\u001b[39m             engine_kwargs=engine_kwargs,\n\u001b[32m  10398\u001b[39m             args=args,\n\u001b[32m  10399\u001b[39m             kwargs=kwargs,\n\u001b[32m  10400\u001b[39m         )\n\u001b[32m> \u001b[39m\u001b[32m10401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m op.apply().__finalize__(self, method=\u001b[33m\"apply\"\u001b[39m)\n",
      "\u001b[32m~/Desktop/PROJECT 24-0048 (CII Prototype Strain Bioreactor Validation)/venv/lib/python3.12/site-packages/pandas/core/apply.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    912\u001b[39m         \u001b[38;5;66;03m# raw\u001b[39;00m\n\u001b[32m    913\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self.raw:\n\u001b[32m    914\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.apply_raw(engine=self.engine, engine_kwargs=self.engine_kwargs)\n\u001b[32m    915\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.apply_standard()\n",
      "\u001b[32m~/Desktop/PROJECT 24-0048 (CII Prototype Strain Bioreactor Validation)/venv/lib/python3.12/site-packages/pandas/core/apply.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m apply_standard(self):\n\u001b[32m   1062\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self.engine == \u001b[33m\"python\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m             results, res_index = self.apply_series_generator()\n\u001b[32m   1064\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m             results, res_index = self.apply_series_numba()\n\u001b[32m   1066\u001b[39m \n",
      "\u001b[32m~/Desktop/PROJECT 24-0048 (CII Prototype Strain Bioreactor Validation)/venv/lib/python3.12/site-packages/pandas/core/apply.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1077\u001b[39m \n\u001b[32m   1078\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"mode.chained_assignment\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;28;01min\u001b[39;00m enumerate(series_gen):\n\u001b[32m   1080\u001b[39m                 \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m                 results[i] = self.func(v, *self.args, **self.kwargs)\n\u001b[32m   1082\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m isinstance(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m                     \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m                     \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n",
      "\u001b[32m~/Desktop/PROJECT 24-0048 (CII Prototype Strain Bioreactor Validation)/optinome_app.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(val)\u001b[39m\n\u001b[32m     81\u001b[39m     - float \u001b[38;5;28;01mor\u001b[39;00m int (assumed already \u001b[38;5;28;01min\u001b[39;00m hours)\n\u001b[32m     82\u001b[39m     - \u001b[33m'HH:MM:SS'\u001b[39m\n\u001b[32m     83\u001b[39m     - \u001b[33m'H:MM'\u001b[39m\n\u001b[32m     84\u001b[39m     Handles the case where `val` \u001b[38;5;28;01mis\u001b[39;00m a pandas Series/array by\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     collapsing it to a single scalar first.\n\u001b[32m     86\u001b[39m     \"\"\"\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# If val is a vector (Series/Index/array/list), collapse to one element\u001b[39;00m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m pandas \u001b[38;5;28;01mas\u001b[39;00m pd\n",
      "\u001b[32m~/Desktop/PROJECT 24-0048 (CII Prototype Strain Bioreactor Validation)/venv/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1578\u001b[39m     @final\n\u001b[32m   1579\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __nonzero__(self) -> NoReturn:\n\u001b[32m-> \u001b[39m\u001b[32m1580\u001b[39m         raise ValueError(\n\u001b[32m   1581\u001b[39m             f\"The truth value of a {type(self).__name__} is ambiguous. \"\n\u001b[32m   1582\u001b[39m             \u001b[33m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[39m\n\u001b[32m   1583\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "from optinome_app import PROJECT_DIR, build_master\n",
    "master = build_master(PROJECT_DIR)\n",
    "print(\"Master shape:\", master.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ac5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: []\n",
      "\n",
      "Features: ['time_hours', 'do_data', 'air_slph', 'agitation_rpm', 'ph_data', 'feed_total_used']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Modeling ===\n",
    "from pathlib import Path\n",
    "\n",
    "out_dir = Path(\"reports\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "report_path = out_dir / \"model_report_template.txt\"\n",
    "report_path.write_text('\\n'.join(report))\n",
    "report = []\n",
    "def nnon(col): return int(master[col].notna().sum()) if col in master.columns else 0\n",
    "\n",
    "targets = [t for t in ['od600','collagen'] if nnon(t)>=25]\n",
    "features = ['time_hours','do_pv','do_sp','feed_ml_h','do_data','air_slph','agitation_rpm','ph_data','glycerol','methanol','feed_total_used']\n",
    "present = [f for f in features if f in master.columns and nnon(f)>=25]\n",
    "report.append(f'Targets: {targets}\\n')\n",
    "report.append(f'Features: {present}\\n')\n",
    "\n",
    "models = {}\n",
    "for tgt in targets:\n",
    "    df_t = master.dropna(subset=[tgt]).copy()\n",
    "    feats = [f for f in present if f in df_t.columns]\n",
    "    df_t = df_t.dropna(subset=feats, how='all')\n",
    "    if df_t.shape[0] < 35 or len(feats)<2:\n",
    "        report.append(f'{tgt}: insufficient rows after cleaning (rows={df_t.shape[0]}, feats={len(feats)}).\\n')\n",
    "        continue\n",
    "    X = df_t[feats].fillna(0.0).values\n",
    "    y = pd.to_numeric(df_t[tgt], errors='coerce').values\n",
    "    mask = np.isfinite(y); X=X[mask]; y=y[mask]\n",
    "    if len(y)<35:\n",
    "        report.append(f'{tgt}: insufficient finite rows ({len(y)}).\\n')\n",
    "        continue\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    r2s, maes = [], []\n",
    "    for tr, te in kf.split(X):\n",
    "        mdl = Ridge(alpha=1.0).fit(X[tr], y[tr])\n",
    "        yp = mdl.predict(X[te])\n",
    "        r2s.append(r2_score(y[te], yp)); maes.append(mean_absolute_error(y[te], yp))\n",
    "    ridge = Ridge(alpha=1.0).fit(X, y)\n",
    "    rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X, y)\n",
    "    models[tgt] = {\n",
    "        'features': feats,\n",
    "        'ridge_coef': list(ridge.coef_),\n",
    "        'ridge_intercept': float(ridge.intercept_),\n",
    "        'cv_r2_mean': float(np.mean(r2s)),\n",
    "        'cv_r2_std': float(np.std(r2s)),\n",
    "        'cv_mae_mean': float(np.mean(maes)),\n",
    "        'rf_feature_importances': dict(zip(feats, rf.feature_importances_.tolist())),\n",
    "        'rows': int(len(y))\n",
    "    }\n",
    "    report.append(f'[{tgt}] R2: {np.mean(r2s):.3f} Â± {np.std(r2s):.3f} | MAE: {np.mean(maes):.4g} | rows: {len(y)}\\n')\n",
    "\n",
    "# Save report\n",
    "\n",
    "print('\\n'.join(report))\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361c421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Visualization ===\n",
    "if not master.empty:\n",
    "    m = master.dropna(subset=['time_hours'])\n",
    "    if 'od600' in m.columns and m['od600'].notna().sum()>3:\n",
    "        plt.figure(); plt.plot(m['time_hours'], m['od600'], '.', alpha=0.7)\n",
    "        plt.xlabel('Time (h)'); plt.ylabel('OD600'); plt.title('OD vs Time'); plt.grid(True)\n",
    "    if 'collagen' in m.columns and m['collagen'].notna().sum()>3:\n",
    "        plt.figure(); plt.plot(m['time_hours'], m['collagen'], '.', alpha=0.7)\n",
    "        plt.xlabel('Time (h)'); plt.ylabel('Collagen'); plt.title('Collagen vs Time'); plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6edd163",
   "metadata": {},
   "source": [
    "**Artifacts**  \n",
    "- `/mnt/data/model_inputs_snapshot_template.csv`  \n",
    "- `/mnt/data/model_report_template.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9872d47d",
   "metadata": {},
   "source": [
    "# Suggestions & Optimization\n",
    "\n",
    "Data-driven levers from your models + literature-backed ranges for *Pichia pastoris* AOX1 induction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a5716c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Suggestions & Optimization for LivenProteins (OD600 & Collagen) ===\n",
      "\n",
      "=== Recommended set-points / strategies ===\n",
      "â€¢ DO setpoint: 25â€“35% during induction; avoid <15%.\n",
      "â€¢ Temperature: 22â€“28Â°C during induction (try 25â€“26Â°C).\n",
      "â€¢ pH: 5.2â€“5.8 (start 5.5).\n",
      "â€¢ Agitation/Air: maintain DO (increase airflow first, then rpm).\n",
      "â€¢ Methanol: ramp to residual 0.5â€“2.0 g/L; adapt after glycerol is depleted.\n",
      "â€¢ Co-feed: sorbitol 20â€“50% of carbon during induction.\n",
      "â€¢ Phases: glycerol batch â†’ derepression â†’ MeOH adaptation â†’ induction.\n",
      "â€¢ Residuals: glycerol ~0 g/L in induction; methanol steady in target band.\n",
      "\n",
      "=== Next-run recipe (edit) ===\n",
      "A) Glycerol batch: OD600 50â€“100 @ 28â€“30Â°C, pH 5.5, DO>35%.\n",
      "B) Derepression: 2â€“4 h low glycerol feed, DO~30%, 26â€“28Â°C; deplete glycerol.\n",
      "C) MeOH adaptation: ramp ~0.5 g/L/h to residual 0.5â€“1.0 g/L (2â€“4 h).\n",
      "D) Induction (18â€“48 h): DO 25â€“35%, 25â€“26Â°C, pH 5.5; hold MeOH 0.5â€“2.0 g/L; sorbitol 20â€“40% carbon.\n",
      "\n",
      "=== DoE screening (3Ã—3Ã—3 + co-feed) ===\n",
      "Factors: DO 25/30/35%; Temp 22/25/28Â°C; MeOH 0.5/1.0/2.0 g/L; Sorbitol 0/0.25/0.5.\n",
      "Responses: collagen titer, STY, OD600, qP, residual MeOH.\n",
      "QC gates: glycerol â‰¤0.5 g/L; MeOH oscillations â‰¤Â±0.5 g/L; DO never <15% for >10 min; pH within Â±0.2.\n"
     ]
    }
   ],
   "source": [
    "# ==== SUGGESTIONS & OPTIMIZATION ====\n",
    "import numpy as np, pandas as pd\n",
    "print(\"=== Suggestions & Optimization for LivenProteins (OD600 & Collagen) ===\\n\")\n",
    "try:\n",
    "    _models = models\n",
    "except NameError:\n",
    "    _models = {}\n",
    "def top_features(mod, k=5):\n",
    "    if not mod: return []\n",
    "    if \"rf_feature_importances\" in mod and mod[\"rf_feature_importances\"]:\n",
    "        items = list(mod[\"rf_feature_importances\"].items())\n",
    "        return [f\"{a}: {b:.3f}\" for a,b in sorted(items, key=lambda x: -x[1])[:k]]\n",
    "    elif \"features\" in mod and \"ridge_coef\" in mod:\n",
    "        import numpy as _np\n",
    "        items = list(zip(mod[\"features\"], _np.abs(mod[\"ridge_coef\"])))\n",
    "        return [f\"{a}: {b:.3f}\" for a,b in sorted(items, key=lambda x: -x[1])[:k]]\n",
    "    return []\n",
    "for target in (\"od600\",\"collagen\"):\n",
    "    if target in _models:\n",
    "        m=_models[target]\n",
    "        cv=m.get('cv_r2_mean',None); std=m.get('cv_r2_std',0.0); rows=m.get('rows','?')\n",
    "        if cv is not None: print(f\"[Model insights] {target.upper()}\\n - CV R2 â‰ˆ {cv:.3f} (Â±{std:.3f}) | rows={rows}\")\n",
    "        tf=top_features(m,6)\n",
    "        if tf: print(\" - Top drivers:\", \", \".join(tf))\n",
    "        print()\n",
    "print(\"=== Recommended set-points / strategies ===\")\n",
    "print(\"â€¢ DO setpoint: 25â€“35% during induction; avoid <15%.\")\n",
    "print(\"â€¢ Temperature: 22â€“28Â°C during induction (try 25â€“26Â°C).\")\n",
    "print(\"â€¢ pH: 5.2â€“5.8 (start 5.5).\")\n",
    "print(\"â€¢ Agitation/Air: maintain DO (increase airflow first, then rpm).\")\n",
    "print(\"â€¢ Methanol: ramp to residual 0.5â€“2.0 g/L; adapt after glycerol is depleted.\")\n",
    "print(\"â€¢ Co-feed: sorbitol 20â€“50% of carbon during induction.\")\n",
    "print(\"â€¢ Phases: glycerol batch â†’ derepression â†’ MeOH adaptation â†’ induction.\")\n",
    "print(\"â€¢ Residuals: glycerol ~0 g/L in induction; methanol steady in target band.\\n\")\n",
    "if 'master' in globals():\n",
    "    import numpy as _np\n",
    "    if {'glycerol','methanol'}.issubset(set(master.columns)):\n",
    "        g = master['glycerol'].dropna(); m = master['methanol'].dropna()\n",
    "        if len(g): print(f\"Observed glycerol: {g.min():.3g}â€“{g.max():.3g} (median {g.median():.3g})\")\n",
    "        if len(m): print(f\"Observed methanol: {m.min():.3g}â€“{m.max():.3g} (median {m.median():.3g})\"); print()\n",
    "print(\"=== Next-run recipe (edit) ===\")\n",
    "print(\"A) Glycerol batch: OD600 50â€“100 @ 28â€“30Â°C, pH 5.5, DO>35%.\")\n",
    "print(\"B) Derepression: 2â€“4 h low glycerol feed, DO~30%, 26â€“28Â°C; deplete glycerol.\")\n",
    "print(\"C) MeOH adaptation: ramp ~0.5 g/L/h to residual 0.5â€“1.0 g/L (2â€“4 h).\")\n",
    "print(\"D) Induction (18â€“48 h): DO 25â€“35%, 25â€“26Â°C, pH 5.5; hold MeOH 0.5â€“2.0 g/L; sorbitol 20â€“40% carbon.\\n\")\n",
    "print(\"=== DoE screening (3Ã—3Ã—3 + co-feed) ===\")\n",
    "print(\"Factors: DO 25/30/35%; Temp 22/25/28Â°C; MeOH 0.5/1.0/2.0 g/L; Sorbitol 0/0.25/0.5.\")\n",
    "print(\"Responses: collagen titer, STY, OD600, qP, residual MeOH.\")\n",
    "print(\"QC gates: glycerol â‰¤0.5 g/L; MeOH oscillations â‰¤Â±0.5 g/L; DO never <15% for >10 min; pH within Â±0.2.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Optinome (venv)",
   "language": "python",
   "name": "optinome"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
